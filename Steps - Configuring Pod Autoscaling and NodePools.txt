You will deploy a sample application to your cluster using the web.yaml deployment file that has been created for you:
To create a deployment from this file, execute the following command
kubectl create -f web.yaml --save-config

Create a service resource of type NodePort on port 8080 for the web deployment.
kubectl expose deployment web --target-port=8080 --type=NodePort

Autoscaler commands
kubectl autoscale deployment web --max 4 --min 1 --cpu-percent 1

Inspect the HorizontalPodAutoscaler object
*******************************************
The kubectl autoscale command you used in the previous task creates a HorizontalPodAutoscaler object that targets a specified resource, called the scale target, and scales it as needed. The autoscaler periodically adjusts the number of replicas of the scale target to match the average CPU utilization that you specify when creating the autoscaler.

To get the list of HorizontalPodAutoscaler resources, execute the following command:
kubectl get hpa

To inspect the configuration of HorizontalPodAutoscaler in YAML form, execute the following command:
kubectl describe horizontalpodautoscaler web

To view the configuration of HorizontalPodAutoscaler in YAML form, execute the following command:
kubectl get horizontalpodautoscaler web -o yaml


Test the autoscale configuration
**********************************
You need to create a heavy load on the web application to force it to scale out. You create a configuration file that defines a deployment of four containers that run an infinite loop of HTTP queries against the sample application web server.

You create the load on your web application by deploying the loadgen application using the loadgen.yaml file that has been provided for you.
kubectl apply -f loadgen.yaml

Get the list of deployments to verify that the load generator is running
kubectl get deployment

Inspect HorizontalPodAutoscaler.
kubectl get hpa

After a few minutes, inspect the HorizontalPodAutoscaler again.
kubectl get hpa

To stop the load on the web application, scale the loadgen deployment to zero replicas.
kubectl scale deployment loadgen --replicas 0

Get the list of deployments to verify that loadgen has scaled down.
kubectl get deployment